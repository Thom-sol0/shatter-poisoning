[DATASET]
dataset_package = decentralizepy.datasets.CIFAR10
dataset_class = CIFAR10
model_class = LeNet
; correct the path to the data
train_dir = /home/pouponne/decentralized/shatter-poisoning/eval/data/CIFAR10
test_dir = /home/pouponne/decentralized/shatter-poisoning/eval/data/CIFAR10
; python list of fractions below
sizes =
random_seed = 90
partition_niid = dirichlet
alpha = 0.1
test_batch_size = 128

[OPTIMIZER_PARAMS]
optimizer_package = torch.optim
optimizer_class = SGD
lr = 0.01

[TRAIN_PARAMS]
training_package = decentralizepy.training.Training
training_class = Training
rounds = 1
full_epochs = True
batch_size = 32
shuffle = True
loss_package = torch.nn
loss_class = CrossEntropyLoss

[COMMUNICATION]
comm_package = decentralizepy.communication.TCP
comm_class = TCP
addresses_filepath = /home/pouponne/decentralized/shatter-poisoning/test_scripts/reproducing_shatter/CIFAR10/ip.json
offset = 9050

[SHARING]
sharing_package = virtualNodes.sharing.VNodeSharingAttackRandomLOSS
sharing_class = VNodeSharingAttackRandomLOSS
compress = False
; Only attack every attack_after rounds
attack_after = 10
; Toggle to enable or disable attacking
perform_attack = True
; Number of received model chunks to attack -> helps speed up experiments
attack_random = 4
; will_receive should be set to k * graph_degree
will_receive = 4

[NODE]
; k in SHATTER
vnodes_per_node = 1
; Degree of the topology, each node has graph_degree neighbors
; Test other values ?
graph_degree = 4
; dynamic = True means that a new topology is generated at each round
dynamic = True
; Restricting threads per proc to reduce contention
threads_per_proc = 1
; Initial model is slightly perturbed
perturb_model = True
perturb_multiplier = 4
